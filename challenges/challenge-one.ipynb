{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GaiaSaveri/intro-to-ml/blob/main/challenges/challenge-one.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7085776",
      "metadata": {
        "id": "a7085776"
      },
      "source": [
        "# Challenge 1: The banknote-authentication data set problem"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7470076a",
      "metadata": {
        "id": "7470076a"
      },
      "source": [
        "We will perform a nearly realistic analysis of the data set bank note authentication that can be downloaded from https://archive-beta.ics.uci.edu/dataset/267/banknote+authentication"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7d1976d",
      "metadata": {
        "id": "d7d1976d"
      },
      "source": [
        "## Data set description\n",
        "\n",
        "Data were extracted from images that were taken from genuine and forged banknote-like specimens. For digitization, an industrial camera usually used for print inspection was used. The final images have 400x 400 pixels. Due to the object lens and distance to the investigated object gray-scale pictures with a resolution of about 660 dpi were gained. Wavelet Transform tool were used to extract features from images.\n",
        "These features are:\n",
        "1. variance of Wavelet Transformed image (continuous) \n",
        "2. skewness of Wavelet Transformed image (continuous) \n",
        "3. curtosis of Wavelet Transformed image (continuous) \n",
        "4. entropy of image (continuous) \n",
        "5. class (integer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "958852e7",
      "metadata": {
        "id": "958852e7"
      },
      "source": [
        "## Task description\n",
        "We have a binary classification problem. The assignment can be divided in several parts:\n",
        "    \n",
        "    1. Load the data and pretreatment.\n",
        "    2. Data exploring by Unsupervised Learning techniques.\n",
        "    3. Construction of several models of Supervised Learning."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feabe205",
      "metadata": {
        "id": "feabe205"
      },
      "source": [
        "### 1. Data pretreatment\n",
        "\n",
        "Load the data and look at it: It is needed some kind of scaling? Why? Are the data points sorted in the original data set? Can it generate problems? How can this be solved?"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cf2boXBSzPkA"
      },
      "id": "Cf2boXBSzPkA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4961a5b9",
      "metadata": {
        "id": "4961a5b9"
      },
      "source": [
        "### 2. Unsupervised Learning\n",
        "\n",
        "Use PCA and plot the two first components colouring according with the class. Are the classes linearly separable in this projection? What happens when I applied k-means with two classes in this space? And if I use all the coordinates? Try also t-SNE for projection and DBSCAN for the clustering and comment on the results."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RLjUm6d2ziK5"
      },
      "id": "RLjUm6d2ziK5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3b00d564",
      "metadata": {
        "id": "3b00d564"
      },
      "source": [
        "### 3. Supervised Learning\n",
        "\n",
        "Generate a subset of the data of 372 elements that would be saved as test set. With the rest of the data generate the following models: Logistic Regression, Decision tree (use the ID3 algorithm), Naive Bayesian and k-NN. \n",
        "\n",
        "Investigate the effect of regularization (when possible) and use cross validation for setting the hyper-parameters when needed. \n",
        "\n",
        "Compare the performances in terms of accuracy, precision, recall and F1-score on the test set. Comment these results at the light of those obtained from the Unsupervised Learning analysis. Could you propose a way to improve these results?     \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d25d2518",
      "metadata": {
        "id": "d25d2518"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}